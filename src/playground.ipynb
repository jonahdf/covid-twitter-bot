{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my notebook file for playing around with new features, testing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sodapy import Socrata\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import data_processing as dp\n",
    "import definitions\n",
    "import data_viz as dv\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "import plotly.express as px\n",
    "import definitions\n",
    "import kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n",
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Fetched all raw data\n",
      "LOG: Processed CDC data\n",
      "LOG: Filtered Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: Added HHS Provisional data\n",
      "LOG: Got raw CDC data\n",
      "LOG: Done getting data\n"
     ]
    }
   ],
   "source": [
    "dp.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.generate(path=\"../\")\n",
    "# #dp.test_data\n",
    "# dp.get_us_positivity()\n",
    "# # dp.get_state_positivity([\"CA\"])\n",
    "# print(dp.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_hosps = dp.get_all_state_hosps()\n",
    "hosp_fig = px.choropleth(state_hosps, locations='State', locationmode=\"USA-states\", color=\"Hospitalizations per Million\", scope=\"usa\", color_continuous_scale='YlOrRd')\n",
    "hosp_fig.update_layout(\n",
    "    title={\n",
    "        'text': \"USA Hospitalizations per Million\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    coloraxis_colorbar_title=\"\")\n",
    "        \n",
    "hosp_fig.show()\n",
    "pio.kaleido.scope.default_scale = 10\n",
    "hosp_fig.write_image(\"../images/maps/hosps.jpeg\")\n",
    "# case_fig = px.choropleth(state_cases, locations='State', locationmode=\"USA-states\", color=\"Cases\", scope=\"usa\", color_continuous_scale='Purples')\n",
    "# case_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_rt = dp.get_all_state_rt()\n",
    "hosp_fig = px.choropleth(state_rt, locations='State', locationmode=\"USA-states\", color=\"Rt\", scope=\"usa\", color_continuous_scale='YlOrRd')\n",
    "hosp_fig.update_layout(\n",
    "    title={\n",
    "        'text': \"USA Weekly Growth in Hospitalizations\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'},\n",
    "    coloraxis_colorbar_title=\"Rt\")\n",
    "pio.kaleido.scope.default_scale = 10\n",
    "hosp_fig.write_image(\"../images/maps/rt.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_cases = pd.DataFrame(columns=['State', 'Cases'])\n",
    "for state in definitions.states.keys():\n",
    "    state_data = dp.get_state_cases([state], start_date=(pd.Timestamp.today() - pd.Timedelta(days=7)).date()) # adjust end date here\n",
    "    if state_data.empty:\n",
    "        cases = False\n",
    "    else:\n",
    "        cases = state_data[state_data['date'] == state_data['date'].max()].cases.values\n",
    "        \n",
    "        cases = cases[0]/definitions.populations[definitions.states[state]]*1000000\n",
    "        state_cases = state_cases.append({\"State\":state, \"Cases\": float(cases)}, ignore_index=True)\n",
    "case_fig = px.choropleth(state_cases, locations='State', locationmode=\"USA-states\", color=\"Cases\", scope=\"usa\", color_continuous_scale='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Covid-Twitter-Bot-Dashboard'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Hospitalizations per capita\n",
    "    ''', justify=\"center\", align=\"center\"),\n",
    "\n",
    "    dcc.Graph(\n",
    "    id='example-graph',\n",
    "    figure=case_fig\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(\n",
    "    id='example-grap2h',\n",
    "    figure=hosp_fig\n",
    "    ),\n",
    "    \n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "cdc_client = Socrata(\"data.cdc.gov\", None)\n",
    "cdc_state_raw = cdc_client.get(\"pwn4-m3yp\", select=\"state, start_date, end_date, new_cases, new_deaths\", limit=2000000)\n",
    "cdc_state_df = pd.DataFrame.from_records(cdc_state_raw)\n",
    "cdc_state_df.start_date = pd.to_datetime(cdc_state_df.start_date)\n",
    "cdc_state_df.end_date = pd.to_datetime(cdc_state_df.end_date)\n",
    "cdc_state_df.new_cases = cdc_state_df.new_cases.astype(float)\n",
    "cdc_state_df.new_deaths = cdc_state_df.new_deaths.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_state_data \n",
    "Creates dataframe of time series weekly date and data for given state\n",
    "inputs:\n",
    " state_codes: List of 2-letter codes of states to query\n",
    " start_date (pd.Timestamp): starting date, defaults to 1-1-2020\n",
    " end_date (pd.Timestamp): ending date, defaults to today \n",
    " normalize: boolean, whether to normalize by state population\n",
    " dataset: dataset to use, defaults to CDC dataset\n",
    " colName: Name of column containing data to add to dataframe\n",
    "returns:\n",
    " df with 'week_start_date', 'week_end_date', and data\n",
    "\"\"\"\n",
    "def get_state_data_weekly(state_codes, start_date = pd.Timestamp(2020,1,1), end_date = pd.Timestamp.today(), normalize=True, dataset = cdc_state_df, colName = 'new_cases'):\n",
    "    curr_date = start_date\n",
    "    input_states = [definitions.states[s] for s in state_codes]\n",
    "    state_data = dataset[dataset.state.isin(state_codes)][:]\n",
    "    max_date = state_data.end_date.max()\n",
    "    states_population = sum([definitions.populations[s] for s in input_states])\n",
    "    lst = []\n",
    "    while(curr_date <= end_date and curr_date <= max_date):\n",
    "        if not (curr_date in state_data['end_date'].values):\n",
    "            curr_date += datetime.timedelta(1)\n",
    "            continue\n",
    "        week_data = state_data[state_data.end_date == curr_date] \n",
    "        if normalize:\n",
    "            case_sum = week_data[colName].sum() / states_population * 1000000\n",
    "        else:\n",
    "            case_sum = week_data[colName].sum()\n",
    "        newRow = {'week_start_date': curr_date - datetime.timedelta(6), 'week_end_date': curr_date, colName: case_sum}\n",
    "        lst.append(newRow)\n",
    "        curr_date += datetime.timedelta(1)\n",
    "    return pd.DataFrame(lst)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/cdc.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# ca_cases = dp.get_state_data_weekly(['CA', 'IL'], normalize=False, dataset=cdc_state_df, colName='new_cases')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# usa_cases = dp.get_all_state_data_weekly(dataset=cdc_state_df, normalize=True, colName='new_cases')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(usa_cases)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m newestData \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39;49mDataSets(from_csv \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/src/data_processing.py:8\u001b[0m, in \u001b[0;36mDataSets.__init__\u001b[0;34m(self, to_csv, from_csv)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, to_csv\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, from_csv\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcdc_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_cdc(from_csv)\n\u001b[1;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhospitalization_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_hosps(from_csv)\n\u001b[1;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_tests(from_csv)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/src/data_processing.py:16\u001b[0m, in \u001b[0;36mDataSets.get_cdc\u001b[0;34m(self, from_csv)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cdc\u001b[39m(\u001b[39mself\u001b[39m, from_csv):\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m (from_csv):\n\u001b[0;32m---> 16\u001b[0m         cdc_loaded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/cdc.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m         cdc_loaded\u001b[39m.\u001b[39mstart_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(cdc_loaded\u001b[39m.\u001b[39mend_date)\n\u001b[1;32m     18\u001b[0m         cdc_loaded\u001b[39m.\u001b[39mend_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(cdc_loaded\u001b[39m.\u001b[39mend_date)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:462\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    459\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    461\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    464\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:819\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwds:\n\u001b[1;32m    817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 819\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:1050\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1047\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown engine: \u001b[39m\u001b[39m{\u001b[39;00mengine\u001b[39m}\u001b[39;00m\u001b[39m (valid options are \u001b[39m\u001b[39m{\u001b[39;00mmapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[39m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1050\u001b[0m \u001b[39mreturn\u001b[39;00m mapping[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:1867\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1864\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39musecols\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols\n\u001b[1;32m   1866\u001b[0m \u001b[39m# open handles\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_handles(src, kwds)\n\u001b[1;32m   1868\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py:1362\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_handles\u001b[39m(\u001b[39mself\u001b[39m, src: FilePathOrBuffer, kwds: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[39m    Let the readers open IOHanldes after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1363\u001b[0m         src,\n\u001b[1;32m   1364\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1365\u001b[0m         encoding\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1366\u001b[0m         compression\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1367\u001b[0m         memory_map\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1368\u001b[0m         storage_options\u001b[39m=\u001b[39;49mkwds\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1369\u001b[0m     )\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/common.py:647\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m         errors \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m     \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    648\u001b[0m         handle,\n\u001b[1;32m    649\u001b[0m         ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    650\u001b[0m         encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    651\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    652\u001b[0m         newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    653\u001b[0m     )\n\u001b[1;32m    654\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/cdc.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ca_cases = dp.get_state_data_weekly(['CA', 'IL'], normalize=False, dataset=cdc_state_df, colName='new_cases')\n",
    "# usa_cases = dp.get_all_state_data_weekly(dataset=cdc_state_df, normalize=True, colName='new_cases')\n",
    "# print(usa_cases)\n",
    "newestData = dp.DataSets(from_csv = True)\n",
    "# dv.plot_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of data_viz failed: Traceback (most recent call last):\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/src/data_viz.py\", line 381, in <module>\n",
      "    newestData = dp.DataSets(from_csv= True)\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/src/data_processing.py\", line 8, in __init__\n",
      "    self.cdc_data = self.get_cdc(from_csv)\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/src/data_processing.py\", line 16, in get_cdc\n",
      "    cdc_loaded = pd.read_csv(\"data/cdc.csv\")\n",
      "  File \"/Users/jonahdf/Local Documents/covid-twitter-bot/ctb/lib/python3.9/site-packages/pandas/io/parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/cdc.csv'\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_state_positivity() got multiple values for argument 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[189], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m dv\u001b[39m.\u001b[39;49mplot_graphs(region \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mCalifornia\u001b[39;49m\u001b[39m\"\u001b[39;49m, path \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m../\u001b[39;49m\u001b[39m'\u001b[39;49m, data \u001b[39m=\u001b[39;49m newestData)\n",
      "File \u001b[0;32m~/Local Documents/covid-twitter-bot/src/data_viz.py:117\u001b[0m, in \u001b[0;36mplot_graphs\u001b[0;34m(region, start_date, end_date, path, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m     l2, l3, l4 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCases per Million\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIn Hospital per Million\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDeaths per Million\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     normalize \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m pos \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39;49mget_state_positivity(definitions\u001b[39m.\u001b[39;49mregions[region], start_date, end_date, dataset \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mtest_data)\n\u001b[1;32m    118\u001b[0m case \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39mget_state_data_weekly(definitions\u001b[39m.\u001b[39mregions[region], start_date, end_date, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, colName\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnew_cases\u001b[39m\u001b[39m'\u001b[39m, dataset \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcdc_data)\n\u001b[1;32m    119\u001b[0m death \u001b[39m=\u001b[39m dp\u001b[39m.\u001b[39mget_state_data_weekly(definitions\u001b[39m.\u001b[39mregions[region], start_date, end_date, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, colName\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnew_deaths\u001b[39m\u001b[39m'\u001b[39m, dataset \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcdc_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_state_positivity() got multiple values for argument 'dataset'"
     ]
    }
   ],
   "source": [
    "a = \"hi\"\n",
    "dv.plot_graphs(region = \"California\", path = '../', data = newestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_state_df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California', 'Illinois']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[definitions.states[s] for s in ['CA', 'IL']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79045504b32d333c12020abfacd4b78f7ca1727b8c61957f0c85e5454cf6a9bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
